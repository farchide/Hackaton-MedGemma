version: "3.9"

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "7860:7860"
    environment:
      - DTT_DEMO_DB=/app/.cache/demo.db
      - PYTHONUNBUFFERED=1
    volumes:
      - dtt-data:/app/.cache
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/"]
      interval: 30s
      timeout: 10s
      start_period: 15s
      retries: 3

  # Optional GPU-enabled service for MedGemma inference.
  # Uncomment and use: docker compose --profile gpu up
  app-gpu:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "7860:7860"
    environment:
      - DTT_DEMO_DB=/app/.cache/demo.db
      - PYTHONUNBUFFERED=1
      - TRANSFORMERS_CACHE=/app/.cache/huggingface
    volumes:
      - dtt-data:/app/.cache
      - huggingface-cache:/app/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    profiles:
      - gpu

volumes:
  dtt-data:
  huggingface-cache:
