# ADR-011: Safety, Ethics & PHI Handling

## Status

Accepted

## Date

2026-02-11

## Context

The Digital Twin Tumor system uses medical imaging AI (MedGemma, MedSAM) to analyze
radiology scans, track tumor progression, and generate natural-language narratives about
disease trajectory. This places the system squarely in the domain of health AI, which
carries significant safety, ethical, and regulatory obligations even for a research
prototype and hackathon submission.

Key concerns:

1. **Clinical misuse risk**: Users could mistake AI-generated tumor analysis or growth
   projections for clinical diagnoses or treatment recommendations. MedGemma's own
   documentation explicitly warns against clinical use.
2. **Protected Health Information (PHI)**: DICOM files routinely contain patient name,
   date of birth, medical record number, and other HIPAA-defined identifiers. The system
   must prevent accidental exposure or persistence of PHI.
3. **Counterfactual projections**: The growth model and "what-if" scenario features
   generate hypothetical future states. Users must clearly understand these are
   mathematical extrapolations, not validated clinical predictions.
4. **Data provenance**: Datasets used for demonstration must have clear licensing,
   documented de-identification status, and transparent sourcing.
5. **Audit trail**: For reproducibility and accountability, all user interactions that
   modify data or trigger AI inference should be logged.
6. **Regulatory landscape**: WHO guidance on AI for health (2021), FDA Good Machine
   Learning Practice (GMLP) principles (2021), and the EU AI Act (2024) all establish
   expectations for transparency, human oversight, and risk management in health AI.

This ADR establishes the safety architecture as a foundational, non-negotiable layer
that applies across all system components.

## Decision

We adopt a **safety-first design with multiple defensive layers**. No single safety
mechanism is considered sufficient; defense in depth is required.

### 1. Non-Clinical Disclaimer Strategy

Disclaimers are displayed at three levels:

**UI Level** (always visible):
- A persistent banner in the application header reading:
  > "RESEARCH PROTOTYPE -- NOT FOR CLINICAL USE. This system is not a medical device
  > and must not be used for clinical diagnosis or treatment decisions."
- The banner uses high-contrast warning styling (yellow/black or red/white) and cannot
  be dismissed or minimized.

**AI Output Level** (per MedGemma response):
- Every narrative generated by MedGemma is prefixed with:
  > "[AI-Generated Analysis] This output is produced by an AI model for research
  > purposes only. It has not been reviewed by a medical professional and must not
  > be used for clinical decision-making."
- This prefix is hard-coded in the prompt post-processing pipeline and cannot be
  removed by configuration.

**Counterfactual Output Level** (per projection):
- All growth projections and what-if scenarios include:
  > "HYPOTHESIS PROJECTION -- This is a mathematical extrapolation based on limited
  > data points and a simplified growth model. It is not a clinical prediction and
  > must not inform treatment decisions."

**Documentation Level**:
- The project writeup and README include a dedicated "Intended Use & Limitations"
  section that mirrors MedGemma's own usage restrictions.
- The Kaggle notebook includes a markdown cell at the top with the full disclaimer.

### 2. PHI Handling & DICOM De-identification

**Ingestion Gate**: All DICOM files pass through a de-identification gate before any
processing occurs. This gate is implemented as a mandatory pipeline stage that cannot
be bypassed.

The de-identification process follows **HIPAA Safe Harbor** (45 CFR 164.514(b)(2))
which requires removal of 18 categories of identifiers:

| DICOM Tag        | Tag ID       | Action    |
|------------------|--------------|-----------|
| PatientName      | (0010,0010)  | Remove    |
| PatientID        | (0010,0020)  | Replace with hash |
| PatientBirthDate | (0010,0030)  | Remove    |
| PatientSex       | (0010,0040)  | Retain (not PHI per Safe Harbor) |
| PatientAge       | (0010,1010)  | Retain if age < 90; remove if >= 90 |
| PatientAddress   | (0010,1040)  | Remove    |
| ReferringPhysicianName | (0008,0090) | Remove |
| InstitutionName  | (0008,0080)  | Remove    |
| InstitutionAddress | (0008,0081) | Remove   |
| StationName      | (0008,1010)  | Remove    |
| StudyDate        | (0008,0020)  | Date-shift (random offset per patient) |
| SeriesDate       | (0008,0021)  | Date-shift (same offset) |
| AccessionNumber  | (0008,0050)  | Replace with hash |
| OtherPatientIDs  | (0010,1000)  | Remove    |
| PatientTelephoneNumbers | (0010,2154) | Remove |

Implementation uses `pydicom` to read and modify DICOM headers. A verification step
after de-identification scans all remaining tags against a deny-list of known PHI tags
and raises an error if any are found.

**No Real Patient Data in Demo Mode**: The system includes a `DEMO_MODE=true` flag
(default for hackathon submission). In demo mode:
- Only pre-approved synthetic or public datasets can be loaded.
- The upload endpoint rejects files and displays a message directing users to the
  included sample data.
- The UI displays a "SYNTHETIC DATA" badge on all visualizations.

Approved public datasets for demonstration:
- TCIA (The Cancer Imaging Archive) collections with documented de-identification
- Medical Segmentation Decathlon subsets (open license)
- Synthetically generated phantoms created by the team

### 3. MedGemma Safety Configuration

**System Prompt Hardening**: MedGemma receives a hard-coded system prompt that is
prepended to every inference call and cannot be overridden by user input:

```
You are a medical imaging analysis assistant for research purposes only.
You are NOT a doctor and must NOT provide clinical diagnoses, treatment
recommendations, or medical advice. If asked for clinical guidance, respond:
"I cannot provide clinical recommendations. Please consult a qualified
healthcare professional."

Your role is limited to:
- Describing visible findings in medical images
- Summarizing measurement trends
- Generating structured reports of observations
- Comparing findings across timepoints

Always caveat observations with uncertainty language (e.g., "appears to show",
"measurements suggest", "findings are consistent with").
```

**Refusal Behaviors**: The system prompt includes explicit refusal instructions for:
- Direct treatment recommendations ("Should I continue chemotherapy?")
- Prognosis statements ("How long does the patient have?")
- Drug dosing or selection
- Surgical planning
- Any request that implies the output will be used for patient care

**Prompt Injection Defense**: User-provided text (e.g., clinical context notes) is
wrapped in delimiters and the system prompt includes an instruction to ignore any
instructions within the user text block.

### 4. Audit Trail

All user-initiated actions are logged to a structured audit log:

```python
@dataclass
class AuditEntry:
    timestamp: str          # ISO 8601
    session_id: str         # Unique session identifier
    action: str             # e.g., "lesion_selected", "measurement_edited"
    component: str          # e.g., "lesion_tracker", "growth_model"
    parameters: dict        # Action-specific parameters
    user_id: str            # Anonymous session-based ID (no real identity)
    data_hash: str          # SHA-256 of input data for reproducibility
```

Logged actions include:
- Dataset loading (which dataset, which timepoints)
- Lesion selection and de-selection
- Measurement edits (old value, new value)
- Counterfactual parameter changes (which parameter, old value, new value)
- MedGemma inference requests (prompt hash, not full prompt to avoid PHI leakage)
- Segmentation runs (model, parameters)
- Lesion identity overrides (see ADR-010)
- Export actions (what was exported, format)

The audit log is stored as a JSONL file at:
```
data/audit/{session_id}_audit.jsonl
```

Audit logs never contain PHI. Patient identifiers in log entries use the
de-identified hash ID only.

### 4a. PostgreSQL-Backed Audit Storage

In addition to the JSONL file-based audit log (which serves as a local fallback),
audit entries are persisted to a PostgreSQL table for transactional integrity,
queryability, and durability. The `ruvnet/ruvector-postgres` Docker image provides
both PostgreSQL and RuVector in a single container.

**Schema:**

```sql
CREATE TABLE audit_log (
    id SERIAL PRIMARY KEY,
    event_id UUID NOT NULL DEFAULT gen_random_uuid(),
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    session_id VARCHAR(64) NOT NULL,
    action VARCHAR(128) NOT NULL,
    component VARCHAR(64),
    user_id VARCHAR(64),
    data_hash VARCHAR(64),
    parameters JSONB,
    INDEX idx_audit_session (session_id),
    INDEX idx_audit_action (action),
    INDEX idx_audit_timestamp (timestamp)
);
```

**Benefits:**

- **SQL queries for audit analysis.** Compliance officers or developers can run
  queries such as "show all measurement edits for patient X across all sessions"
  or "count all RECIST override events in the last 30 days" without parsing
  log files.
- **JSONB parameters field.** The `parameters` column stores action-specific data
  (e.g., old/new measurement values, lesion coordinates) as flexible JSON, enabling
  ad hoc queries without schema changes.
- **Indexed queries for compliance reporting.** The indexes on `session_id`,
  `action`, and `timestamp` support fast filtered queries for regulatory audits
  and usage analytics.
- **Transactional guarantees.** PostgreSQL ACID transactions ensure that audit
  entries are either fully written or not at all, preventing partial or corrupted
  log entries that can occur with file-based JSONL under crash conditions.
- **Tamper detection.** RuVector's security verification features provide additional
  tamper detection on audit records (see Section 5a).

### 5. Data Provenance Tracking

Every loaded dataset carries a provenance record:

```python
@dataclass
class DataProvenance:
    dataset_name: str           # e.g., "TCIA-NSCLC-Radiomics"
    source_url: str             # Download URL
    license: str                # e.g., "CC BY 3.0"
    deidentification_method: str # e.g., "TCIA CTP pipeline"
    deidentification_verified: bool
    original_study_reference: str # DOI or publication reference
    download_date: str          # When the team obtained the data
    notes: str                  # Any additional context
```

The provenance record is displayed in the UI data panel and included in all exported
reports. The system refuses to process datasets without a provenance record when
`DEMO_MODE=true`.

### 5a. RuVector Security Features

RuVector (provided by the `ruvnet/ruvector-postgres` Docker image) includes built-in
security verification capabilities that strengthen the safety and integrity posture
of the Digital Twin Tumor system:

- **Tamper detection on stored vectors and metadata.** RuVector can detect unauthorized
  modifications to stored vectors and their associated metadata. This is particularly
  valuable for audit records and measurement embeddings, where post-hoc tampering
  would undermine the integrity of the audit trail.
- **Vector-based semantic PHI detection.** PHI scanning can be enhanced beyond simple
  keyword matching by embedding known PHI patterns (names, dates, medical record
  number formats) as vectors in RuVector. Incoming text and metadata fields are
  embedded and compared against these patterns using semantic similarity search,
  catching PHI that keyword rules might miss (e.g., misspelled names, reformatted
  dates, abbreviated identifiers).
- **Cryptographic hash logging.** All vector operations (inserts, updates, deletions)
  are logged with cryptographic hashes, creating a tamper-evident chain. If any record
  is modified outside the normal application flow, the hash chain will break,
  triggering an integrity alert.

These features complement the existing DICOM de-identification gate (Section 2) by
adding a secondary detection layer that operates on semantic content rather than
structured DICOM tags alone.

### 6. iRECIST Disclaimer

All RECIST/iRECIST-related outputs include:

> "Response assessments shown here follow iRECIST conventions for measurement and
> categorization. These automated assessments are for research and educational purposes
> only and have not been adjudicated by a qualified radiologist. They must not be used
> for clinical treatment decisions or trial endpoint determination."

### 7. Regulatory & Ethics References

The project writeup includes explicit references to:

- **WHO Ethics & Governance of AI for Health** (2021): Principles of protecting human
  autonomy, promoting human well-being, ensuring transparency, and fostering
  responsibility.
- **FDA Good Machine Learning Practice (GMLP)** (2021): Specifically Principle 1
  (multi-disciplinary expertise), Principle 3 (representative data), Principle 6
  (model transparency), and Principle 10 (monitoring deployed models).
- **HIPAA Safe Harbor De-identification Standard** (45 CFR 164.514(b)(2)): The
  specific regulatory basis for our de-identification approach.
- **MedGemma Model Card**: All usage restrictions from Google's published model card
  are respected and referenced.

## Consequences

### Positive

- Multiple independent safety layers mean no single failure can expose users to
  unmitigated clinical risk.
- DICOM de-identification at ingestion prevents PHI from ever reaching downstream
  components, reducing the blast radius of any data leak.
- Hard-coded system prompts prevent prompt injection from removing safety guardrails
  from MedGemma outputs.
- The audit trail enables post-hoc analysis of system usage for both debugging and
  safety review.
- Explicit regulatory references demonstrate awareness of the health AI governance
  landscape and strengthen the hackathon submission.
- Demo mode with synthetic-only data eliminates PHI risk entirely for the hackathon
  evaluation.
- PostgreSQL provides queryable, durable audit storage with transactional guarantees,
  enabling SQL-based compliance reporting and eliminating the risk of corrupted or
  partial log entries that can occur with file-based JSONL storage.

### Negative

- Pervasive disclaimers may create visual noise and reduce the polish of the demo
  experience. This is an acceptable trade-off for safety.
- The de-identification gate adds processing time at ingestion (~1-2s per DICOM
  series). This is negligible relative to downstream model inference.
- Hard-coded MedGemma system prompts reduce flexibility for users who might want
  different AI behaviors. This inflexibility is intentional.
- Audit logging adds I/O overhead. For the expected usage patterns (interactive,
  single-user), this is negligible.

### Risks

- De-identification may miss PHI embedded in private DICOM tags or burned into pixel
  data. Mitigation: the system flags private tags for manual review and the
  documentation notes that pixel-level PHI (burned-in annotations) is out of scope
  for automated removal.
- MedGemma may generate clinically-sounding language despite the system prompt.
  Mitigation: output post-processing adds disclaimers regardless of model compliance.
- Users may ignore disclaimers. Mitigation: this is acknowledged as a limitation; the
  system cannot control user behavior, only inform it.

## Alternatives Considered

### 1. No De-identification (Trust Dataset Providers)

Rely on public datasets being pre-de-identified. Rejected because: DICOM metadata
can be reintroduced accidentally, and the system should be safe by default even if
fed improperly prepared data.

### 2. Disclaimer Only at Application Start

Show a single consent/disclaimer dialog at startup. Rejected because: users habituate
to startup dialogs and may not internalize the limitations. Per-output disclaimers
maintain awareness throughout the session.

### 3. No Audit Trail

Skip logging to reduce complexity. Rejected because: reproducibility and accountability
are core principles of responsible AI development, and the implementation cost is
minimal.

### 4. Dynamic MedGemma System Prompts

Allow configuration of the system prompt for different use cases. Rejected because:
in a medical context, the safety guardrails must not be configurable. The risk of
accidental or intentional removal of safety instructions outweighs the flexibility
benefit.

### 5. Full HIPAA Expert Determination Method

Use statistical methods to verify de-identification rather than Safe Harbor.
Rejected because: Expert Determination requires a qualified statistical expert and
is disproportionate to a hackathon prototype. Safe Harbor provides clear, enumerated
rules that are straightforward to implement and verify.
